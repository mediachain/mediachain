# RFC 4: New Directions in Mediachain: Protocols and Architecture

Status: WIP WIP WIP WIP

Authors: vyzo, parkan

## Lessons from Phase I: It's not a Blockchain

The blockchain is an attractive solution: the public ledger promotes
open data and discovery, while also simplifying streaming for online
processing.

But it comes with significant costs:

* Complexities of maintaining consensus in a peer to peer network.
* PoS/PoW economics that don't quite work in our domain.
* Inefficient querying, requires the entire blockchain for read operations.
* Difficult to scale to large datasets with bulk and firehose ingestion,
  the blockchain becomes the bottleneck.
* Ultimately trying to solve a problem we don't have: double spending.

In reality, we don't need a singular linearly ordered view of the world.
And we want to allow the system to grow to very large datasets (billions
of objects) supporting bulk and firehose ingestion models.

Fundamentally, what we need is a map of media identifiers to sets
of statements that allows us to track and relate media objects.
This has the hallmarks of a CRDT data structure, which allows a system to
achieve eventually consistent state without the need for consensus. 

So what we want to build is a distributed database that supports
_upserts_ connecting statements to one or more domain specific
identifiers. An upsert is an idempotent insert/update operation that
does not require knowledge of the current state of the database. This
allows operations to execute concurrently without requiring locks
or ordering.

It is intended to provide a low level plumbing data structure, as dumb
as possible. Rich relations between objects can be expressed with
merkle DAGs in object content, allowing the application layer to
evolve according to user needs.

### Domain-Specific Identifiers Instead of Opaque Pointers

In the Phase I design, object identifiers were mediachain-issued
opaque pointers generated by content hashes of the initial insert.
Moving forward, we choose to utilize well-known/domain-specific
identifiers (WKI; e.g. moma:190935) with the following motivations:

* It reduces burden of authoritative ID issuance (e.g. DOI) as well as
  authoritatively asserting canonical-instance relationships.
* Most works we are dealing with at this stage will already have an ID established
  by previous use.
* Mapping from a set of WKIs to a set of statements is an elegant way of
  granularly and nondestructively expressing sameness/merges, with potentially
  different "sameness" perspectives represented through namespace relationships.
  For instance, a service like Clarifai can publish a namespace containing only
  merges based on visual similarity
* WKI-based provider records can be reasonably implemented as distributed,
  freeing organizationss from relying on indexers for simple mappings

Works that are mediachain-first and require an identifier can either
generate one or receive it from a ticket server. This ID will be
treated the same way as any other.

### Data Structure Operations

The Phase I data structure interface provided 3 basic operations:
insert, update, and lookup. The insert method ingested an object into
the system and returned its canonical identifier. For each identifier,
the system maintained a chain pointer linking the object to a chain of
updates. The update method updated the chain pointer by consing a new
update object on top of the current chain, while lookup retrieved the
head of the chain for a canonical.

In practice, inserts are idempotent and the chained update model only
serves to constrain the system by imposing order of operations.
By dropping ordering and utilizing domain specific identifiers, we can
eliminate the distinction between insert and update.

The write interface is thus an upsert method, which combines insert
and update, and adds a statement to the set of objects associated with
an identifier. If the system has no prior knowledge of the identifier,
then it creates a new entry in the identifier mapping with a singleton
set containing the object.

The lookup method can be retained as a basic read operation, with a
change at its return value. Since there are no chained updates any
more, the method returns the known set of updates relating to an
identifier. 

### Namespace Partitioning

In order to reflect the natural organization of data according to
institution, industry, topic, etc, we introduce the concept of
namespaces. In terms of scaling, the partitioning must be semantic so
as to allow peers to commit resources only in topics they are
interested in. In terms of administrative control, the partitioning
must be hierarchical so that we can easily delegate management and
moderation to organizational stake holders.

To satisfy these requirements, we've chosen to adopt a hierarchical
structure similar to unix paths. Leaves in the hierarchy map to
specific datasets and provide the primary entry points for writes, and
namespaces higher in the hierarchy aggregate namespaces below and
provide a progressively expanded read view of the data structure. Much
like symlinks with unix paths, alternate views of the hierarchy are
possible, namespaces may have multiple parents, and so on. This
creates a semantically rich and expressive framework for querying and
composition.

### Moderation and Publishing Model

Namespaces allow us fine grained control on publishing and
participation level. At one end of the spectrum, we want to
encourage public namespaces which allow lightweight permissionless
participation. At the other end, we want to support curated namespaces
to combat spam and allow authoritative sources and commercial media
providers to maintain control of their own data.

In order to implement this model, each participating peer has an
associated identity corresponding to a public key. The identities
are intended to be long-lived and eventually have an attached reputation
score.

All statements published in the system are signed with the key of the
source of the statement. In order to publish in a moderated namespace,
the originating peer must present a certificate which allows it to
publish there. Alternatively, it can convince a peer with the right
certificate to publish on its behalf. Certificates can be obtained by
moderators and owners of the namespace. 

This moderation scheme, with delegated administrative control,
attaches a cost to peer identities because certificates can be
revoked. This encourages cooperative behavior by individual peers,
thus avoiding the social cost of cheap identities [1]. At the same
time, individual peers with publishing rights are free to implement
their own authentication for their clients.

### Queries and Aggregation

Namespaces provide a convenient way to request information about the
same object from several different strata. For example, a query for an
image from the NYPL collection and the corresponding OldNYC geocoding
data can look like

```
{nypl:510d47e2-ef28-a3d9-e040-e00a18064a99@nypl,oldnyc}
```

which would mean "return results for WKI nypl:510d47e2-ef28-a3d9-e040-e00a18064a99 from
[nypl](http://digitalcollections.nypl.org/items/510d47e2-ef28-a3d9-e040-e00a18064a99)
and [oldnyc](https://www.oldnyc.org/#1557929) namespaces". NYPL can
also choose to transclude the statment from the `oldnyc` namespace
into `nypl` itself, "blessing" it.

Other possibilities include filtered aggregation (a `lithographs`
namespace that aggregates some objects from `getty`, some from `nypl`,
etc), lazy aggregation (logical aggregates that do not publish a
stream until requested), etc. Exact semantics TBD.


## A Heterogeneous Network of Cooperative Peers

The distributed database is maintained by a heterogeneous peer-to-peer
network. Peers are operated by different organizations and
individuals, and contribute different resources to the network.

Each peer maintains some parts of the dataset and has a limited view
of the mediachain. Peers synchronize their state with peer-to-peer
interactions, and converge their view of the data structure by
exchanging published statements.

Statements can be propagated in the network via push, either with
direct messages or through streaming. For stream propagation, stable
peers form pubsub overlays for their namespaces and emit published
statements to their subscribers. Equally well, peers can poll their
peers for recent updates, allowing them to operate in a disconnected
fashion.

The metadata associated with statements is stored in IPLD, with the
seeding initially supplied by sources. As statements propagate in the
network, peers may opportunistically reseed metadata in order to aid
availability and distribution. More specialized peers can provide
persistent seeding and achiving services for some namespaces, potentially
incentivized through something like Filecoin.

### Peer Roles

Peers can take on a variety of roles like intermittent sources,
firehose publishers, aggregators, indexers, archivers, etc. See the
[Peer Roles](mediachain-rfc-4-roles.md) supplement for specific examples
and case studies.

From an operational perspective, the basic possible role actions are
read/receive, write/publish and aggregate/republish. A peer acts as a
reader when it receives new statements from the network and adds it to
its local store. A peer acts as a writer when it publishes new
statements to the network, which eventually get distributed to
interested readers. Finally, a peer acts as an aggregator when it
reads from multiple namespaces and republishes into an aggregate
namespace.

### The Local Store

Each peer has a local store which serves as a spool for all statements
it has created or received by other peers. Using the local store, the
peer can compute the index that maps identifiers to metadata
statements and answer basic queries.

Peers can operate disconnected and simply manipulate their local view
of the mediachain by adding new statements to the store. Their updates
are buffered in the spool until they connect to the network and
publish them to other peers.

### Statement Publication

In order to propagate statements in the network and synchronize its
local store, a peer needs to discover other peers with publishing
permissions in relevant namespaces. Directory servers facilitate this
interaction: every peer who stays online registers with a directory
server for its namespaces. Thus, a peer just coming online can obtain
a list of peers who are interested in its buffered statements and
can be polled to provide new statements.

A publishing peer who intends to stay online can further proceed to
register with the directory. This makes it discoverable by other peers
who want to publish or read statements in its namespaces.

At this level, the system can already simply work asynchronously, by
having readers periodcally poll publishers for new statements and
writers push new statements to other publishers. It is sufficient to
have a stable population of online publishers, who ensure the eventual
publication of new statements to all readers.

In order to streamline online publication and indexing, stable
publishers can organize into pubsub overlays. The overlay for a
namespace can be constructed by connecting to a subset of other
publishers in a way that maintains connectivity with some redundancy
factor. Readers and aggregators can then connect as downstream clients
from publishers.

Deeper overlay topologies can be constructed by allowing stable
readers to serve as intermediate nodes who relay statements to other
readers (or relays). This is a safe operation, as each statement
carries the signature of a publisher and peers can verify that
signature and associated certificates independently.

### Metadata Ingestion

A fundamental use case for the system is the ability to ingest
pre-existing datasets from authoritative sources in bulk.

The ingestion process first requires a translation step, where
metadata records from the existing dataset are translated to
structured metadata objects for the mediachain. The next step is to
publish the objects in IPLD and obtain their pointers, so that they
can related to media identifiers with statements. Finally, for each
object in the original dataset a statement msut be generated, which
binds the pre-existing object identifier to the metadata object with a
cryptographic signature.

This process follows a straightforward path from existing record to
mediachain statement and may very well work with small datasets.
However, this process is extremely inefficient for large datasets
with millions of artefacts. Firstly, the metadata need to published to
IPLD, a process which may be lengthy and resource hungry. Secondly, a
cryptographic signature needs to be generated for each statement, a
process which is also computationally expensive. And then there is the
traffic required for propagating statements in the network, which can
overload caches and online processors.

In order to address the cost of signatures, the protocol allows for
binding multiple statements together with a single signature. And in
order to address the load issues, the protocol allows for publishing
archives to the network. These archives are tarballs that contain
statements and their associated metadata as separate files named by
their IPLD hashes. A bulk ingesting source can thus avoid the IPLD
publication step and bundle the statements directly with their
metadata objects.  Furthermore, the archive can be distributed
directly to interested readers by using a protocol optimized for bulk
transfer, such as IPFS Bitswap or Bittorrent.

Similar dynamics arise for the use case of firehose sources, which
generate a constant load of new statements, eg by following social
media feeds.  Firehoses don't have to publish every statement in real
time. Instead, they can buffer statements and periodically publish
them together with their metadata as archives. This allows the system
to push high volumes of data without overloading the network.

### Metadata Persistence

### Indexes and Queries

### Database Semantics

### Governance and Public Namespaces

---
## The Mediachain Protocol

WIP WIP WIP WIP WIP

### Identities

Public Key identities for peers and clients
uses:
 statement signing -- statement attribution
 Key signing -- p2p certificates

P2P PKI -- DHT overlay for key publication and sharing;
 all peers participate in the DHT

publish pub keys in DHT (key = identity), together with certificate pointers
in a signed structure; include user name in the record.

DHT interface
 
### Namespaces

hierarchical namespace structure
namespace creation and discovery:  directory servers
group membership, moderation, permission model

some bootstrap namespaces: /u, /contrib, /glam
/u -- unmoderated, free for all
/contrib -- individual contributor space in /contrib/user: personal publication space,
/glam -- curated namespace for organizational data sources: museums, art galleries, etc

### Permissions

moderated namespaces:
peer participation role: reader, publisher, moderator
 reader: has no publish permissions, reads within the namespace
  default public role for moderated namespaces
 publisher: has publish permissions
  can manage its own end users, ultimately signs statement blocks
  propagating in the network, but cannot grant direct publishing
  permissions
 moderator:
  can grant publish permissions
  can revoke publish permissions it can granted
 ownership:
  namespace owners can grant modrerator rights
  group initially owned by creator
  co-ownership by granting ownership
  in co-owned namespaces, moderation rights can be granted by any owner
  or some majority of them, depending on policy
  moderation revocation by similar policy

Namepsace hierarchy:
 namespace ownership:
  can create subnamespaces, and grant ownership
 permission:
  grant create namespace

makes identities for curated namespaces expensive to obtain;
certificate revocation mechanisms

scaling up: governance issue -- we'll be happy to have this problem.

### Certificates

certificate structure and rules for permissions.
revocation.

### Statements

statement structure
 statment-id, ns, src, signature, id refss, , ipld object reference
 it's the header for the object

```
statement = {
 statement-id: <statement-id> ; timestamp
 source: <peer-id>
 namespace: <namespace>
 signature: <signature>
 refs: [<domain-id> ...]
 object: <IPLD-reference>
}

statement-id: <peer-id:timestamp:counter>
```

multi-statements: composite statements signed together, allow simple batching
(signatures can be computationally expernsive operations)

```
multi-statement = {
  statement-id: <statement-id>
  source:  <peer-id>
  namespace: <namespace>
  signature: <signature>
  statements: [<statement-part> ...]
}

statement-part = {
 statement-id: <statement-id>
 refs: [<Id> ...]
 object: <IPLD-Reference>
}
```

### Statement Publication

publishing statements: namespace permissions, authentication by the publishing
peer mediating the target namespace(s)

protocol for publisher: present certificate for namespace together with statement.

blocks and archives

block envelope: group together statements signed by users,
 altogether signed by publishing peer:
it allows light-weight certificate infrastructure, end user certificates are
 managed at the leaves.

update propagation:
 pubsub for online processors
 poll option for disconnected clients:
  queries by timestamp

resilient overlay multicast
backbone (long lived, connected peers) maintaining overlay network for streaming
namespace updates

republishing with extended identifier sets or expanded namespace scope

### Aggregation and Indexing

aggregate pubsub streams of multiple namespaces, clients subscribe to receive
update streams.
indexing: IDs -> statement mapping
republishing: adding ids, posting to multiple namespaces

### Queries

peers answer queries locally -- provide a subset view of the mediachain
query by time range --> [some] blocks since last update
query by peer id
query by id
query by id + set of namespaces

queries not necessary supported by all peers, index requirements.

## Examples

TBD

## References

1. [The Social Cost of Cheap Pseudonyms](http://www.haas.berkeley.edu/Courses/Spring2000/BA269D/FriedmanResnick99.pdf)
